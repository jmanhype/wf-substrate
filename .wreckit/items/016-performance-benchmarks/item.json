{
  "schema_version": 1,
  "id": "016-performance-benchmarks",
  "title": "Implement performance benchmarks",
  "state": "critique",
  "overview": "Implement wf_bench.erl: microbenchmarks measuring executor performance characteristics.\n\nBenchmarks:\n1. Sequence throughput: sequence of 10,000 tasks (trivial no-op tasks), measure total time and steps/sec. Target: demonstrate O(1) per-step cost.\n2. Parallel split+join: par of 100 branches each with a single task, synchronizing join. Measure fork overhead, join overhead, total time.\n3. Repeated discriminator: 1,000 iterations of discriminator pattern (par of 5 branches, first-complete join, cancel remaining 4). Measure cancellation latency per iteration.\n4. Deep nesting: sequence of 100 nested par(seq(task, task), seq(task, task)) â€” deep AST but flat bytecode. Verify that per-step cost does not scale with original AST depth.\n5. Multiple instances: MI with 100 fixed instances, wait_all join. Measure spawn overhead and collection overhead.\n6. State store: 10,000 mutations with periodic commits. Measure commit latency and receipt generation overhead.\n\nReport format: for each benchmark, output {name, steps, wall_time_us, steps_per_sec, memory_words}. Memory measured via erlang:process_info(self(), memory) before and after.\n\nKey invariant to demonstrate: overhead per step is bounded and does not scale with AST size (because we execute flat bytecode, not recursive AST dispatch).\n\nInclude a run_all/0 function that runs all benchmarks and prints a formatted table.",
  "branch": null,
  "pr_url": null,
  "pr_number": null,
  "last_error": null,
  "created_at": "2026-02-10T00:00:00.000Z",
  "updated_at": "2026-02-11T16:46:14.038Z"
}
